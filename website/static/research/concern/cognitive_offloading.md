# Cognitive Offloading & Over-reliance

**19 papers matched** (11 directly addressing this concern)

## Executive Summary

The literature reveals substantial and growing concern about cognitive offloading and over-reliance on AI/LLM tools in K-12 education, with evidence spanning both theoretical frameworks and empirical studies. Multiple papers document how AI tools designed to assist learning can inadvertently create dependency, reduce critical thinking, and bypass the 'productive struggle' essential for deep learning. This concern manifests across multiple educational contexts—from automated question generation and tutoring systems to student use of ChatGPT—with consistent findings that students tend to accept AI-generated content without sufficient verification or critical evaluation. The risk is particularly acute because AI systems are designed for convenience and agreement (the 'comfort-growth paradox'), which can feel empowering while actually constraining cognitive development. Evidence shows students struggle to comprehend AI-generated code, over-rely on AI for tasks they should master independently, and exhibit 'automation bias' where they trust AI outputs even when explicitly warned of potential errors.

However, the literature also identifies promising mitigation strategies through careful pedagogical design. The concept of 'Enhanced Cognitive Scaffolding' proposes that AI should provide temporary, adaptive support that progressively fades as learner competence grows, rather than constant assistance. Studies show that structured learning processes—including pre-use education about AI limitations, limited AI access during tasks to encourage peer/teacher interaction, and post-use verification activities—can reduce over-dependence. The 'extraheric AI' framework specifically advocates for AI that poses questions and alternative perspectives rather than providing direct answers, fostering higher-order thinking. Multiple papers emphasize that AI should augment rather than replace human cognition, requiring explicit teacher training, student digital literacy development, and institutional policies that position AI as a complement to traditional pedagogy. The evidence suggests the risk is real and significant, but manageable through intentional design and implementation that prioritizes cognitive engagement over efficiency.

## Key Findings

### Students exhibit automation bias and over-trust AI outputs even when explicitly warned about potential errors, leading to acceptance of incorrect information without verification

*Evidence type: empirical | 6 papers*

- "I Would Have Written My Code Differently": Beginners Struggle to Understand LLM-Generated Code
- The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review
- ChatGPT in Research and Education: Exploring Benefits and Threats

### AI's design for convenience and user agreement creates a 'comfort-growth paradox' where ease of use reduces cognitive challenge necessary for learning

*Evidence type: theoretical | 3 papers*

- The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox
- Dialogic Pedagogy for Large Language Models
- extraheric AI framework

### Students struggle significantly to comprehend and evaluate AI-generated content, with CS1 students showing only 32.5% success rate in understanding LLM-generated code

*Evidence type: empirical | 4 papers*

- "I Would Have Written My Code Differently": Beginners Struggle to Understand LLM-Generated Code
- Simulated Students in Tutoring Dialogues: Substance or Illusion?
- Next-Step Hint Generation for Introductory Programming Using Large Language Models

### Over-reliance on AI reduces students' critical thinking, analytical reasoning, and problem-solving skills as they favor fast AI solutions over effortful learning

*Evidence type: empirical | 5 papers*

- The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review
- ChatGPT in Research and Education: Exploring Benefits and Threats
- The Impact of Large Language Models on K-12 Education in Rural India

### Structured pedagogical interventions—including pre-use education, limited access during tasks, and post-use verification—can effectively reduce over-dependence on AI

*Evidence type: empirical | 3 papers*

- Using ChatGPT for Science Learning: A Study on Pre-service Teachers' Lesson Planning
- PBL-centered English language course with AI tools
- The Impact of Large Language Models on K-12 Education in Rural India

### Enhanced Cognitive Scaffolding that provides progressive autonomy (high initial support that fades as competence grows) can amplify cognition while preventing dependency

*Evidence type: theoretical | 2 papers*

- The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox
- Dialogic Pedagogy for Large Language Models

### Pre-service teachers recognize over-reliance risks and propose systematic methods including teaching AI limitations, structuring limited AI use, and verification processes

*Evidence type: empirical | 2 papers*

- Using ChatGPT for Science Learning: A Study on Pre-service Teachers' Lesson Planning
- The Impact of Large Language Models on K-12 Education in Rural India

### Students use AI tools more frequently for efficiency tasks (homework, debugging) than for deeper learning activities, with 85-88% using for quick answers

*Evidence type: empirical | 3 papers*

- ChatGPT in Research and Education: Exploring Benefits and Threats
- Impact of ChatGPT on Student's Education
- Next-Step Hint Generation for Introductory Programming Using Large Language Models

## Evidence For This Risk

- Empirical study showing CS1 students achieved only 32.5% success rate in understanding LLM-generated code, with 67.5% failure rate even when code was provided
- Multiple survey studies documenting 75-95% of students report using AI for academic tasks, with majority rarely verifying AI-generated information
- Systematic review identifying that over-reliance on AI dialogue systems demonstrably impacts decision-making, critical thinking, and analytical reasoning abilities
- Experimental evidence of 'automation bias' where students trust AI outputs despite explicit warnings about potential errors and known presence of bugs
- Observation that students 'repeatedly submitted LLM-generated solutions without modification,' suggesting acceptance without understanding
- Finding that 44.7% of students report ChatGPT has negatively impacted their thinking skills, with 36% reporting it discouraged independent problem-solving
- Documentation that AI tools designed to be 'agreeable and low-friction' create confirmation bias and reduce exposure to challenging perspectives
- Evidence that students exhibit 'illusion of competence' when using LLMs, overestimating their coding abilities due to AI assistance
- Teacher observations that students demonstrate reduced effort in crafting well-structured work and show complacency in independent research when AI is available
- Knowledge tracing research showing students can memorize 'answer bias' shortcuts rather than learning underlying concepts when AI provides patterns

## Mitigating Evidence

- Enhanced Cognitive Scaffolding framework showing that AI providing temporary, adaptive support that fades over time can successfully amplify cognition without creating dependency
- Pre-service teachers successfully designed lesson plans incorporating systematic methods to reduce over-dependence: teaching AI limitations before use, structuring limited interaction time, and requiring verification after use
- Evidence that explicit prompting strategies (e.g., Socratic questioning, asking for alternative perspectives rather than answers) can transform AI from answer-provider to thinking partner
- Student volunteers in rural India recognized over-reliance risks and proposed AI as 'complementary tool rather than replacement for traditional teaching'
- Studies showing 79-84% of students find AI helpful for ideation and brainstorming, suggesting productive use cases when positioned appropriately
- Research demonstrating that when AI is embedded within structured learning activities (group discussions, POE method, peer presentations), over-reliance can be tempered
- Evidence that teacher-in-the-loop approaches, where educators guide AI use and provide final evaluation, maintain human oversight and reduce blind acceptance
- Finding that diverse information presentation formats and interactive features in automated reporting systems can promote active engagement rather than passive consumption
- Documentation that students can be trained to use AI critically when institutions implement AI literacy programs emphasizing ethical use and limitations
- Studies showing that hybrid human-AI systems (combining teacher expertise with AI efficiency) produce better outcomes than either alone, suggesting appropriate role division

## What Is Being Measured

- Code comprehension success rates when students evaluate LLM-generated code (32.5% success in one study)
- Frequency of information verification: 56% verify sometimes, 34.7% always, 9.3% never verify AI outputs
- Self-reported impact on critical thinking: 44.7% report negative impact, 34% report yes impact, 21.3% no impact
- Task completion efficiency: time saved, workload reduction measured in teacher and student contexts
- Automation bias through experimental tasks where students accept incorrect AI outputs despite warnings
- Student confidence levels before and after AI use, measuring 'illusion of competence'
- Engagement metrics: frequency of AI use (daily, weekly, monthly), types of tasks performed with AI
- Learning outcomes through pre-post tests comparing groups with/without AI access
- Question quality metrics: answer relevance, coherence, factual consistency, informativeness of AI-generated educational content
- Cognitive load measurements using rubrics based on cognitive load theory and Bloom's taxonomy

## Gaps — What Is NOT Being Measured

- Long-term cognitive development trajectories: whether early AI dependence creates lasting deficits or if students naturally develop critical evaluation skills over time
- Transfer effects: whether over-reliance in AI-assisted domains affects student autonomy and critical thinking in non-AI contexts
- Comparative cognitive effort: actual cognitive processing differences between AI-assisted and traditional learning, not just outcomes
- Threshold effects: at what point does AI assistance transition from helpful scaffolding to harmful dependence
- Recovery potential: whether students who become over-reliant can regain independent thinking skills, and what interventions work
- Domain-specific variations: whether over-reliance manifests differently in STEM vs. humanities vs. language learning
- Developmental differences: how cognitive offloading risks vary across age groups (primary vs. secondary vs. tertiary students)
- Metacognitive awareness: students' ability to recognize when they are over-relying on AI vs. using it appropriately
- Social and collaborative effects: how peer learning dynamics change when AI becomes the primary resource
- Motivation and engagement trade-offs: whether reduced cognitive effort through AI leads to reduced intrinsic motivation for learning

## Context Factors

- Student age and developmental stage: Beginning programmers (CS1 level) show particularly high vulnerability with 67.5% failure rate in code comprehension
- Subject domain: Over-reliance appears more pronounced in technical subjects (programming, mathematics) where AI can provide direct solutions vs. humanities requiring interpretation
- Tool design: AI systems designed for 'convenience and agreement' vs. those designed for 'cognitive challenge and questioning' produce different dependency patterns
- Pedagogical framing: Whether AI is positioned as assistant vs. replacement, with teacher-in-the-loop vs. direct student access affecting outcomes
- Task structure: Open-ended vs. well-defined problems, with AI more likely to short-circuit learning on routine tasks
- Prior knowledge: Students with weaker foundational skills more susceptible to over-reliance; non-native English speakers face additional comprehension barriers
- Institutional policies: Schools with explicit AI literacy training and usage guidelines show better student critical evaluation
- Access patterns: Constant availability (24/7 chatbots) vs. structured, limited access during specific learning activities affects dependency development
- Cultural context: Rural vs. urban settings, resource-constrained environments where AI may be only available 'expert'
- Assessment design: When testing focuses on final products rather than process, AI use for shortcuts increases
- Social learning environment: Individual vs. collaborative contexts, presence of peer interaction opportunities

## Notable Studies

### "I Would Have Written My Code Differently": Beginners Struggle to Understand LLM-Generated Code

**Design:** Lab study with 32 CS1 students across 160 task instances comparing comprehension of natural language prompts vs. LLM-generated code implementations
**Sample:** 32 first-year computer science students (CS1 level), university context
**Key result:** Only 32.5% success rate in code comprehension despite 59.3% success in understanding natural language prompts; students showed automation bias, assuming correctness even with explicit warnings about bugs

### The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review

**Design:** Systematic review using PRISMA guidelines across 14 studies examining relationship between over-reliance on AI and cognitive abilities
**Sample:** Review of 14 articles from ProQuest, IEEE Xplore, ScienceDirect, and Web of Science databases
**Key result:** Over-reliance stemming from ethical issues (hallucinations, biases, privacy) demonstrably impacts decision-making, critical thinking, and analytical reasoning as users favor fast solutions over effortful learning

### Using ChatGPT for Science Learning: A Study on Pre-service Teachers' Lesson Planning

**Design:** Analysis of 29 pre-service teachers' lesson plans integrating ChatGPT into rural K-12 science education, plus semi-structured interviews examining perceptions
**Sample:** 29 pre-service elementary teachers from Korean university planning rural science lessons
**Key result:** 11 of 29 teachers (38%) proposed systematic methods to reduce over-dependence: teaching AI characteristics/pitfalls before use, structuring limited interaction, and requiring verification after use

### The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox

**Design:** Theoretical framework development integrating Vygotskian learning theory with AI design principles, proposing progressive autonomy approach
**Sample:** Theoretical paper with application examples across education, workplace, healthcare contexts
**Key result:** Framework demonstrating how AI can provide high initial support that progressively fades as competence grows, resolving tension between comfort (efficiency) and growth (challenge) through adaptive personalization

### ChatGPT in Research and Education: Exploring Benefits and Threats

**Design:** Mixed methods: subjective experiments demonstrating ChatGPT effectiveness plus surveys of students and teachers on perceived benefits and challenges
**Sample:** Students and teachers in engineering education, survey-based with programming experiments
**Key result:** While 91.4% used ChatGPT for quick answers, 44.7% reported negative impact on thinking skills; 36% reported it discouraged independent problem-solving; only 34.7% always verified AI information

### extraheric AI framework paper

**Design:** Conceptual framework development proposing AI that 'draws forth' higher-order thinking through questioning rather than answering
**Sample:** Theoretical framework with design considerations for implementation
**Key result:** Framework showing AI can pose questions, provide alternative perspectives, and encourage reflection rather than direct answers, reducing over-reliance while fostering critical thinking aligned with cognitive load theory and Bloom's taxonomy

## Implications for LMICs

The cognitive offloading and over-reliance concern has particularly acute implications for low- and middle-income countries (LMICs). Rural Indian educator volunteers highlighted that infrastructure constraints (poor connectivity, limited device access) paradoxically may both exacerbate and mitigate the risk: when AI tools are the only readily available 'expert' resource in teacher-scarce environments, dependency becomes more likely, yet intermittent access may naturally enforce the kind of limited exposure that prevents over-reliance. The 'digital divide' creates a dual risk—students without AI access fall behind in digital literacy, while those with access may lack the foundational skills and teacher support to use AI critically. Non-native English speakers face additional comprehension barriers with primarily English-trained LLMs, increasing both the risk of misunderstanding AI outputs and the temptation to accept them uncritically. In resource-constrained settings where teacher training is limited and class sizes are large, AI tools are especially attractive for efficiency, but the evidence suggests this is precisely where over-reliance risks are highest without structured pedagogical support. The rural Indian teacher study showed that even well-intentioned educators recognize these risks but struggle with how to implement systematic safeguards. For LMICs, the priority should be developing locally-adapted AI literacy programs, creating AI tools with multilingual and low-bandwidth capabilities designed with cognitive scaffolding principles, and ensuring teacher training emphasizes AI as complement rather than replacement—before widespread deployment creates entrenched patterns of dependency.

## Recommendations

- Implement systematic three-phase AI integration: (1) pre-use education about AI capabilities and limitations, (2) structured learning with limited AI access to ensure peer/teacher interaction, (3) post-use verification activities requiring students to evaluate AI outputs critically
- Design AI tools using Enhanced Cognitive Scaffolding principles: provide high initial support that progressively fades as student competence grows, with adaptive personalization that increases challenge as skills develop
- Position AI explicitly as 'cognitive partner' or 'thinking tool' rather than 'answer provider,' using prompting strategies that elicit Socratic questioning and alternative perspectives rather than direct solutions
- Develop and mandate AI literacy curricula covering: how LLMs work, common failure modes (hallucinations, biases), appropriate use cases, and critical evaluation strategies—before students use AI for academic work
- Restructure assessments to measure process over product: focus on problem-solving approach, reasoning quality, and ability to explain/justify solutions rather than just final answers, making AI shortcuts less effective
- Train teachers in AI-aware pedagogy: how to design tasks that benefit from AI assistance without enabling shortcuts, how to detect over-reliance, and how to intervene when students show dependency patterns
- Implement teacher-in-the-loop systems where educators maintain oversight: AI provides support but teachers make final evaluations, review AI suggestions before student access, and guide appropriate use
- Create institutional policies that define appropriate AI use: specify tasks where AI assistance is encouraged (brainstorming, checking work) vs. discouraged (initial problem-solving, concept development), with clear rationale
- Build verification requirements into workflows: require students to fact-check AI outputs against reliable sources, explain AI-generated code in their own words, or compare multiple AI outputs for consistency
- For LMICs specifically: prioritize development of multilingual, low-bandwidth AI tools designed with cognitive scaffolding principles; create culturally-adapted AI literacy programs; ensure teacher training emphasizes AI as complement to traditional pedagogy before widespread deployment

## Top Papers

1. **"I Would Have Written My Code Differently": Beginners Struggle to Understand LLM-Generated Code**
   Provides empirical evidence of comprehension failure (32.5% success) and automation bias in actual student use, directly measuring the core concern

2. **The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox**
   Offers comprehensive theoretical framework with practical design principles for preventing over-reliance through progressive autonomy and adaptive support

3. **The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review**
   Synthesizes evidence across multiple studies documenting measurable impacts on critical thinking, decision-making, and analytical reasoning from AI over-reliance

4. **Using ChatGPT for Science Learning: A Study on Pre-service Teachers' Lesson Planning**
   Demonstrates teacher awareness of over-reliance risks and documents practical systematic methods for mitigation in real classroom planning

5. **extraheric AI: Fostering Higher-Order Thinking Through AI-Driven Questioning**
   Proposes fundamental redesign of human-AI interaction to foster cognitive engagement through questioning rather than answering, addressing root cause of offloading
